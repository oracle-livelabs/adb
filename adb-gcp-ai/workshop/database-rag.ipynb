{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run the RAG application code snippets in Jupyter notebook.\n",
    "\n",
    "Now you're ready to run each code snippet in sequence starting from the top in Jupyter. To run a code snippet, select the cell of the code and click Run to execute the code.\n",
    "\n",
    "When the code snippet has completed running a number will appear in the square brackets. You can then proceed to the next cell and code snippet. Some of the code will print an output so you can get feedback.At any time you can also re-run the code snippets in the Jupyter cell.\n",
    "\n",
    "Python libraries and modules have already been installed for this RAG application. Note the libraries for LangChain and a new library for the Oracle AI Vector Search, OracleVS and Vertex AI, vertexai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "\n",
    "import sys\n",
    "import array\n",
    "import time\n",
    "import oci\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "#from sentence_transformers import CrossEncoder\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.llms import OCIGenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import oraclevs\n",
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "from langchain_core.documents import BaseDocumentTransformer, Document\n",
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "import oracledb\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# suppersing warning messages\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "print(\"Successfully imported libraries and modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. This next code snippet defines the function to include metadata with the chunks. Select the code snippet and click Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format and add metadata to Oracle 23ai Vector Store\n",
    "\n",
    "def chunks_to_docs_wrapper(row: dict) -> Document:\n",
    "    \"\"\"\n",
    "    Converts text into a Document object suitable for ingestion into Oracle Vector Store.\n",
    "    - row (dict): A dictionary representing a row of data with keys for 'id', 'link', and 'text'.\n",
    "    \"\"\"\n",
    "    metadata = {'id': row['id'], 'link': row['link']}\n",
    "    return Document(page_content=row['text'], metadata=metadata)\n",
    "print(\"Successfully defined metadata wrapper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. This code connects to Oracle Database 23ai with the credentials and connection string. Select the code snippet and click Run. Update the code with the Username, Password, Connection String and Wallet Password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "\n",
    "un = \"admin\" # Enter Username\n",
    "pw = \"WElcome##123\" # Enter Password\n",
    "dsn = 'd5kas9zhfydbe31a_high' # Enter Connection String\n",
    "wpwd = \"WElcome##123\" # Enter Wallet Password\n",
    "\n",
    "connection = oracledb.connect(\n",
    "    config_dir = '../wallet', \n",
    "    user=un, \n",
    "    password=pw, \n",
    "    dsn=dsn,\n",
    "    wallet_location = '../wallet',\n",
    "    wallet_password = wpwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the Document -> The document in our use case is in PDF format. We are loading a PDF document and printing the total number of pages, and printing page 1 for your visual feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document\n",
    "\n",
    "# creating a pdf reader object\n",
    "pdf = PdfReader('oracle-database-23ai-new-features-guide.pdf')\n",
    "\n",
    "# print number of pages in pdf file \n",
    "print(\"The number of pages in this document is \",len(pdf.pages)) \n",
    "# print the first page \n",
    "print(pdf.pages[0].extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The code transforms each page of the PDF document to text. Click Run to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the document to text\n",
    "\n",
    "if pdf is not None:\n",
    "  print(\"Transforming the PDF document to text...\")\n",
    "text=\"\"\n",
    "for page in pdf.pages:\n",
    "    text += page.extract_text()\n",
    "print(\"You have transformed the PDF document to text format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Split the text into chunks\n",
    "\n",
    "Our chunk size will be 800 characters, with an overlap of 100 characters with each chunk. Note: Chunk sizes vary depending on the type of document you are embedding. Chat messages may have smaller chunk size, and larger 100 page essays may have larger chunk sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the text document into smaller chunks\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\",chunk_size=800,chunk_overlap=100,length_function=len)\n",
    "chunks = text_splitter.split_text(text)\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The code adds metadata such as id to each chunk for the database table. Click Run to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata wrapper to store additional information in the vector store\n",
    "\"\"\"\n",
    "Converts a row from a DataFrame into a Document object suitable for ingestion into Oracle Vector Store.\n",
    "- row (dict): A dictionary representing a row of data with keys for 'id', 'link', and 'text'.\n",
    "\"\"\"\n",
    "docs = [chunks_to_docs_wrapper({'id': f'{page_num}', 'link': f'Page {page_num}', 'text': text}) for page_num, text in enumerate(chunks)]\n",
    "print(\"Created metadata wrapper with the chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Set up Oracle AI Vector Search and insert the embedding vectors\n",
    "\n",
    "The embedding model used in this lab is **all-MiniLM-L6-v2** from HuggingFace. **docs** will point to the text chunks. The connection string to the database is in the object **connection**. The table to store the vectors and metadata are in **RAG_TAB**. We use **DOTPRODUCT** as the algorithm for the nearest neighbor search. Note: Embedding models are used to vectorize data. To learn more about embedding models, see the LiveLabs on Oracle AI Vector Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an embedding model, embed the chunks as vectors into Oracle Database 23ai.\n",
    "\n",
    "# Initialize embedding model\n",
    "model_4db = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Configure the vector store with the model, table name, and using the indicated distance strategy for the similarity search and vectorize the chunks\n",
    "s1time = time.time()\n",
    "knowledge_base = OracleVS.from_documents(docs, model_4db, client=connection, table_name=\"RAG_TAB\", distance_strategy=DistanceStrategy.DOT_PRODUCT, )     \n",
    "s2time =  time.time()      \n",
    "print( f\"Vectorizing and inserting chunks duration: {round(s2time - s1time, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully uploaded the document, transformed it to text, split into chunks, and embedded its vectors in Oracle Database 23ai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Connect to the database and run a sample query on the table to confirm records were inserted into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"RAG_TAB\"\n",
    "\n",
    "with connection.cursor() as cursor:\n",
    "    # Define the query to select all rows from a table\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Print the rows\n",
    "    for row in rows[:5]:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. The code issues a prompt related to the document we loaded. Click Run to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = 'Tell me more about JSON Relational Duality'\n",
    "print (\"The prompt to the LLM will be:\",user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. The code records the timing for searching the database. It's quick! Click Run to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup timings to check performance\n",
    "\n",
    "# code not needed, only used for measuring timing\n",
    "if user_question:\n",
    "    s3time =  time.time()\n",
    "    result_chunks=knowledge_base.similarity_search(user_question, 5)\n",
    "    print(result_chunks)\n",
    "    s4time = time.time()\n",
    "    print( f\"Search user_question and return chunks duration: {round(s4time - s3time, 1)} sec.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. LLM to generate your response.\n",
    "\n",
    "We will be using Vertex AI for this lab. From your Google Cloud Console confirm the Project ID and region that you want to use and enter the details. Import the library vertexai and initiate Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"proud-research-451713-i5\"  # @param {type:\"string\"}\n",
    "REGION = \"us-east4\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# LangChain\n",
    "import langchain\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "\n",
    "# Utils\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from pydantic import BaseModel\n",
    "\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "# Vertex AI\n",
    "\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. The code below sets up the **Vertex AI Service** to use **gemini-1.5-flash-002**. Click Run to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "# set the LLM to get response\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-1.5-flash-002\",\n",
    "    max_output_tokens=8192,\n",
    "    temperature=1,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. The code below builds the prompt template to include both the question and the context, and instantiates the knowledge base class to use the retriever to retrieve context from Oracle Database 23ai. Click Run to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a template for the question and context, and instantiate the database retriever object\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "            {context} Question: {question} \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "retriever = knowledge_base.as_retriever(search_kwargs={\"k\": 10})\n",
    "print(\"The template is:\",template)\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Invoke the chain\n",
    "\n",
    "This is the key part of the RAG application. It is the LangChain pipeline that chains all the components together to produce an LLM response with context. The chain will embed the question as a vector. This vector will be used to search for other vectors that are similar. The top similar vectors will be returned as text chunks (context). Together the question and the context will form the prompt to the LLM for processing. And ultimately generating the response.\n",
    "\n",
    "The code defines the RAG chain process and invokes the chain. Click Run to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the entire process together, retrieve the context, construct the prompt with the question and context, and pass to LLM for the response\n",
    "\n",
    "s5time = time.time()\n",
    "print(\"We are sending the prompt and RAG context to the LLM, wait a few seconds for the response...\")\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke(user_question)\n",
    "print(user_question)\n",
    "print(prompt)\n",
    "print(response)\n",
    "# Print timings for the RAG execution steps\n",
    "\n",
    "s6time = time.time()\n",
    "print(\"\")\n",
    "print( f\"Send user question and ranked chunks to LLM and get answer duration: {round(s6time - s5time, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done with this lab. You can proceed to the next lab.\n",
    "\n",
    "Click Run to execute the congrats code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Congratulations! You've completed your RAG application with AI Vector Search in Oracle Database 23ai running on Oracle Database@Google Cloud using LangChain\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
