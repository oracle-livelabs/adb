# Introduction

## About this Workshop

This workshop will show you how to use Data Studio's Data Transforms tool to create a data pipeline in order to engineer data for data analysis, data science, or AI. Data can be loaded from a wide selection of heterogenous sources (databases and applications) and can go through complex transformations. You will learn how to define the data load and transforms process and schedule them for periodic execution.

Estimated Workshop Duration: 2 hours, 30 minutes

### Who should use this Workshop?

This workshop is useful for anyone who needs to have a detailed knowledge of loading and transforming data in the Autonomous Database. 

### Objectives

In this workshop, you will learn:
-	How to create a connection to your data sources and targets
-   How to import entity definitions
-	How to load data without any transformation
-	How to load and transform data 
-   How to create data flows
-   How to schedule your execution

### Prerequisites

Before you launch into this workshop, you will need the following:

- Basic knowledge of Oracle Cloud
- Basic level of understanding of SQL query language

### How to use the Workshop

The labs are ordered in a sequence. Start with creating the users and importing the data. If you have the pre-created environment then you can skip these. The rest of the workshop takes you through various tasks you need to execute in order to build a data pipeline in the Data Transforms tool.

A data pipeline consists of the following components:

- A Data Load job: For extracting data from the source and loading to the target without any transformations. A Data Load job can be used to extract data from one, many, or all source tables in a schema, and load corresponding tables in the target database.
- A Data Flow: You can design complex transformations in a data flow from any set of source tables to your target table.
- A Workflow: You can execute multiple data load and data flow jobs in a single workflow so that they can be executed as an unit.

For this workshop we will use demo movie streaming and customer demographics data for a fictional movie streaming company. The goal of creating the data pipeline is to populate a set of tables that can be used to analyze customer movie watching behavior. The details will be explained further in individual labs.


If you have any questions about the topics covered in this lab and the entire workshop, please contact us by posting on our public forum on  **[cloudcustomerconnect.oracle.com](https://cloudcustomerconnect.oracle.com/resources/32a53f8587/)**  and we will respond as soon as possible.

## Acknowledgements

- Created By/Date - Jayant Mahto, Product Manager, Autonomous Database, January 2023
- Contributors - Mike Matthews
- Last Updated By - Jayant Mahto, July 2024


Copyright (C)  Oracle Corporation.


